{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "* Like numpy but allows us to use GPU for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "* Torchvision is an accompanying library to pyTorch. It contains some data set loaders, and a Dataset class you may extend if you wish.\n",
    "* torch.utils.data works with the DataSet class to provide data loaders. It's a complex class so if you use it, just use it as is.\n",
    "* Alternatively you can write your own loader code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Data\n",
    "* You will want to train on some of the data, and test with the rest. We will provide you with the split.\n",
    "\n",
    "## Tensors\n",
    "* The default loader class will create instances of PyTorch Tensors. They're like Numpy arrays, but can also reside on your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic transforms. Normalize(0.5, 0.5) will set that mean and std-dev\n",
    "# Based on statistics of the data\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = dset.MNIST(root='./mnist_data', train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root='./mnist_data', train=False, transform=trans)\n",
    "N = 8\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=N, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=N, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data\n",
    "* Notice the transpose! Though these are black/white images, you'll need to swap channels around to get normal colors.\n",
    "* If you normalize your data, you may have to recenter it before displaying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "imshow(grid)\n",
    "print \" \".join([\"%s\" % i for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (images[0].shape)\n",
    "D_in = 28 * 28 # size of input\n",
    "H = 400     # size of hidden layer\n",
    "D_out = 10    # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H)\n",
    "w2 = torch.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6 # learning rate\n",
    "iters = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        ## Forward pass ##     \n",
    "        # flatten image\n",
    "        imgs.resize_((N, D_in)) \n",
    "        # multiply by hidden layer weights\n",
    "        h = imgs.mm(w1)\n",
    "        # non-linearity (RELU)\n",
    "        h_relu = h.clamp(min=0)\n",
    "        # multiply hidden layer by second set of weights\n",
    "        y_pred = h_relu.mm(w2)\n",
    "        \n",
    "        ## Calculate Loss ##\n",
    "        # Get categorical representation of label\n",
    "        y = torch.eye(10)[labels]\n",
    "\n",
    "        # SSD\n",
    "        #loss = (y_pred - y).pow(2).sum()\n",
    "        y_diff = y_pred - y\n",
    "        y_pow = y_diff.pow(2)\n",
    "        loss = y_pow.sum()\n",
    "        print \"Epoch = %d, Loss = %f\" % (epoch, loss)\n",
    "            \n",
    "        ## Back propagation ##\n",
    "        # Back propagate loss\n",
    "        d_y_pow = loss\n",
    "        d_y_diff = 2.0 * 1.0 * y_diff\n",
    "        d_y_pred = d_y_diff\n",
    "        # Multiplication: del x (x*y) = y, del y (x * y) = x\n",
    "        d_w2 = h_relu.t().mm(d_y_pred)\n",
    "        d_h_relu = d_y_pred.mm(w2.t())\n",
    "        d_h = d_h_relu.clone()\n",
    "        d_h[h < 0] = 0\n",
    "        d_w1 = imgs.t().mm(d_h)\n",
    "\n",
    "        # Update weights using gradient descent\n",
    "        w1 -= learning_rate * d_w1\n",
    "        w2 -= learning_rate * d_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "imshow(grid)\n",
    "print \"Ground Truth:\", \" \".join([\"%s\" % i for i in labels])\n",
    "\n",
    "## Predict\n",
    "y_pred = imgs.resize_((N, D_in)).mm(w1).clamp(min=0).mm(w2) \n",
    "y_pred = np.argmax(y_pred.numpy(), axis=1)\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "* Doing differentiation by ourselves for back-propagation is a lot of work. PyTorch can do it for us.\n",
    "* We'll use the Variable class to wrap Tensors and maintain a computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "D_in = 28 * 28 # size of input\n",
    "H1 = 400     # size of 1st hidden layer\n",
    "H2 = 100\n",
    "D_out = 10    # number of classes\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = Variable(torch.randn(D_in, H1), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H1, H2), requires_grad=True)\n",
    "w3 = Variable(torch.randn(H2, D_out), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6 # learning rate\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        ## Forward pass ##     \n",
    "        # flatten image\n",
    "        imgs = Variable(imgs.resize_((N,28*28)), requires_grad=False)\n",
    "        \n",
    "        # do all calculations (no need to stage, Autograd will take care of it)\n",
    "        y_pred = imgs.mm(w1).clamp(min=0).mm(w2).clamp(min=0).mm(w3)\n",
    "\n",
    "        ## Calculate Loss ##\n",
    "        # Get categorical representation of label\n",
    "        y = Variable(torch.eye(10)[labels], requires_grad=True)\n",
    "        # MSE\n",
    "        loss = (y_pred - y).pow(2).mean()\n",
    "        #print \"y_pred = \", y_pred.data\n",
    "        #print \"y = \", y.data\n",
    "        print \"Epoch = %d, Loss = %f\" % (epoch, loss.data[0])\n",
    "\n",
    "        ## Back propagation ##        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights directly\n",
    "        w1.data -= learning_rate * w1.grad.data\n",
    "        w2.data -= learning_rate * w2.grad.data\n",
    "        \n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.data.zero_()\n",
    "        w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "imshow(grid)\n",
    "print \"Ground Truth:\", \" \".join([\"%s\" % i for i in labels])\n",
    "\n",
    "## Predict\n",
    "y_pred = imgs.mm(w1).clamp(min=0).mm(w2).clamp(min=0).mm(w3)\n",
    "print y_pred\n",
    "y_pred = np.argmax(y_pred.data.numpy(), axis=1)\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn Module\n",
    "* We'd like to automate the low-level design\n",
    "* Put together Layers that perform certain functionality, like Legos\n",
    "* High level interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "D_in = 28 * 28 # size of input\n",
    "H1 = 400     # size of 1st hidden layer\n",
    "H2 = 100\n",
    "D_out = 10    # number of classes\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, H1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H1, H2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H2, D_out)\n",
    ")\n",
    "\n",
    "# We have pre-built loss functions available to us\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss_fn = nn.MSELoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for imgs, labels in train_loader:\n",
    "    x = Variable(imgs.resize_((N,28*28)), requires_grad=False)\n",
    "    #y = Variable(torch.eye(10)[labels], requires_grad=False)\n",
    "\n",
    "    y = Variable(labels)\n",
    "    # forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print loss.data[0]\n",
    "    \n",
    "    # zero the gradients\n",
    "    model.zero_grad()   \n",
    "\n",
    "    # backward pass\n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    # update parameters using gradient\n",
    "    for param in model.parameters():\n",
    "        param.data -= learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "imshow(grid)\n",
    "print \"Ground Truth:\", \" \".join([\"%s\" % i for i in labels])\n",
    "\n",
    "## Predict\n",
    "x = Variable(imgs.resize_((N,28*28)), requires_grad=False)\n",
    "y_pred = model(x)\n",
    "print y_pred\n",
    "y_pred = np.argmax(y_pred.data.numpy(), axis=1)\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "* We've been updating parameters directly with gradient descent, but there are better algorithms.\n",
    "* e.g. Adam\n",
    "* These algorithms simulate momentum and other effects to do more than just step in the direction of least gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "D_in = 28 * 28 # size of input\n",
    "H1 = 500     # size of 1st hidden layer\n",
    "H2 = 200\n",
    "D_out = 10    # number of classes\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, H1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H1, H2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H2, D_out)\n",
    ")\n",
    "\n",
    "# We have pre-built loss functions available to us\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "        x = Variable(imgs).view(-1, 28*28) # Notice how we flatten\n",
    "        y = Variable(labels)\n",
    "    \n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "              \n",
    "        # backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "    \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print \"Epoch %d, Batch %d Loss %f\" % (epoch, batch_idx, loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "dataiter = iter(test_loader)\n",
    "images, _ = dataiter.next()\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "imshow(grid)\n",
    "print \"Ground Truth:\", \" \".join([\"%s\" % i for i in labels])\n",
    "\n",
    "# Predict\n",
    "x = Variable(images).view(-1, 28*28)\n",
    "y_pred = model(x)\n",
    "print y_pred\n",
    "_, classes = torch.max(y_pred, 1)\n",
    "print classes\n",
    "\n",
    "# Accuracy\n",
    "count = 0\n",
    "correct = 0\n",
    "for images, labels in test_loader:\n",
    "    count += N\n",
    "    x = Variable(images).view(-1, 28*28)\n",
    "    y_pred = model(x)\n",
    "    _, classes = torch.max(y_pred, 1)\n",
    "    correct += np.count_nonzero(labels.numpy() == classes.data.numpy())\n",
    "\n",
    "print \"Accuracy is \",(correct / float(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom modules\n",
    "* We can define our own modules with our own behavior.\n",
    "* Inherit from nn.Module and override forward()\n",
    "* Can contain other modules and autograd Variables.\n",
    "* Can be custom loss modules.\n",
    "\n",
    "## GPU\n",
    "* We wanted to use the GPU, right?\n",
    "* .cuda() method will move a Tensor/Variable to the GPU\n",
    "* If we want to examine a Variable, we now need to transfer to CPU using .cpu()\n",
    "\n",
    "## Saving/Loading your Model\n",
    "* Very important! Cloud instances can be lost easily.\n",
    "* Use `torch.save(the_model.state_dict(), PATH)` to save, and `the_model.load_state_dict(torch.load(PATH))` to load.\n",
    "* When submitting, we'll want your state and program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
